---
title: "Collective Autonomous Air Mobility Systems"
excerpt: "Encouraging emergent coordination in collective autonomous air mobility systems."
header:
    teaser: /assets/images/research/uam.jpeg
tags:
  - artificial intelligence
  - intelligent transportation systems
  - multi-agent systems
  - reinforcement learning
  - robotics
last_modified_at: 2024-09-20
---

We work on methods for coordinating many agents in collective autonomous air mobility systems (CAAMS), like urban air mobility and drone firefighting. We specifically aim to encourage emergent cooperation in CAAMS, with consideration of heterogeneity (e.g., individual objectives, capabilities) and the overall integrated system (e.g., vehicles and their interactions with operators and services).
<!-- Our key ideas are to learn from existing collective autonomous sytems (eCAS), like autonomous vehicles and biological systems, and leverage insights gained from such systems to create new multi-agent reinforcement learning (MARL) algorithms. -->

This work is funded in part by NASA 80NSSC23M0221 and ONR N00014-20-1-2249.

<div class="funding-logos">
    <a href="https://www.nasa.gov/"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/funding/nasa.jpg"></a>
    <a href="https://www.onr.navy.mil/"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/funding/onr.png"></a>
</div>

## Predicting social cost of self-interested agents

This work explores ways to evaluate and predict the social cost induced by agents acting according to their own selfish objectives. Our approach leverages value functions from policies optimized for the social objective, modeled as a multi-agent Markov decision process (MMDP), and individual agent objectives, modeled as a Markov game (MG), to **predict a social cost metric for any given state.**

## A survey of applications of inverse reinforcement learning in aviation

This work surveys current applications of inverse reinforcement learning (IRL) in aviation. We also identify potential challenges of using IRL for aviation, which may explain its current limited use within the field, and identify potential future applications of IRL for aviation.
