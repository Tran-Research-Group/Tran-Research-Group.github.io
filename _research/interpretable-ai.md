---
title: "Interpretable AI Agents"
excerpt: "Interpreting or explaining artificial intelligence-based autonomous agents."
header:
    teaser: /assets/images/research/ltl.png
tags:
  - artificial intelligence
  - controls
  - reinforcement learning
last_modified_at: 2025-01-17
---

We work on methods to interpret or explain autonomous agents, with a focus on those that use artificial intelligence-based decision making policies.

This work was funded in part by ONR N00014-20-1-2249.

<div class="funding-logos">
    <a href="https://www.onr.navy.mil/"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/funding/onr.png"></a>
</div>

## Searching for temporal logic explanations of reinforcement learning agents

<figure-full-caption>
	<a href="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"></a>
	<figcaption>A partial trace of our search method with weighted Kullback-Leibler (KL) divergence values used to determine which nodes to expand.</figcaption>
</figure-full-caption>

This work proposes a greedy search over a class of **temporal logic formulae** to infer human-interpretable explanations of reinforcement learning policies. See our IEEE Control Systems Letters paper for more details.

<div class="row">
    <a href="https://arxiv.org/pdf/2309.16960" class="button_general">arXiv</a>
    <a href="https://doi.org/10.1109/LCSYS.2024.3519301" class="button_general">DOI</a>
</div>